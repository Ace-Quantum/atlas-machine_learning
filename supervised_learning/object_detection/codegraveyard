    #     # assign height, width, and anchors from each output
    #     grid_height, grid_width, num_anchors = output.shape[:3]

    #     # set up arrays for the current output
    #     current_boxes = np.zeros((grid_height, grid_width, num_anchors, 4))
    #     current_box_confidences = np.zeros((grid_height, grid_width, num_anchors, 1))
    #     current_box_class_probs = np.zeros((grid_height, grid_width, num_anchors, output.shape[3] - 5))

    #     # For each cell in the grid
    #     for r in range(grid_height):
    #         for c in range(grid_width):
    #             for a in range(num_anchors):
    #                 # tx and ty - center of the bounding box
    #                 # tw and th - normalized height and width of bounding box
    #                 # conf - confidence score of if the box contains an object
    #                 # class probs - the probabilities for each class
    #                 tx, ty, tw, th, conf, *class_probs = output[r, c, a]

    #                 # Scale the bounding box
    #                 x1 = (tx * image_width / grid_width) - (tw / 2)
    #                 y1 = (ty * image_height / grid_height) - (th / 2)
    #                 x2 = (tx * image_width / grid_width) + (tw / 2)
    #                 y2 = (ty * image_height / grid_height) + (th /2)

    #                 # Store the newly processed bounding box
    #                 current_boxes[r, c, a] = [x1, y1, x2, y2]

    #                 # Store the box_confidences
    #                 current_box_confidences[r, c, a] = conf

    #                 # Store the probabilities
    #                 current_box_class_probs[r, c, a] = class_probs

    #     boxes.append(current_boxes)
    #     box_confidences.append(current_box_confidences)
    #     box_class_probs.append(current_box_class_probs)

    # return boxes, box_confidences, box_class_probs

    #     processed_boxes = output[:, :, :, :4]

    #     # convert coordinates
    #     processed_boxes[..., :2] = (processed_boxes[..., :2] + np.indices((
    #         output.shape[0], output.shape[1])).T) / (output.shape[0], output.shape[1])
        
    #     processed_boxes[..., 2:4] = np.exp(processed_boxes[..., 2:4]) * self.model.anchors / image_size

    #     # extract confidences
    #     box_confidence = output[:, :, :, 4:5]

    #     # extract class probabilities
    #     box_class_prob = output[:, :, :, 5:]

    #     boxes.append(processed_boxes)
    #     box_confidences.append(box_confidence)
    #     box_class_probs.append(box_class_prob)

    # return boxes, box_confidences, box_class_probs

    # This is not dead code but rather code that I want to look at with color coding:
    def extractInfo(modelOutput, anchors, numClass):
        featureDim = modelOutput.shape
        numAnchor = anchors.shape[0]  # get the number of anchors, 5 for the Pascal dataset
        modelOutput = tf.reshape(modelOutput, shape=(-1, featureDim[1], featureDim[2], numAnchor, numClass + 5))
        """
        Now modelOutput has shape (-1, grid num W, grid num H, anchor num, 5+class num)
        For bounding box k in grid (i, j) in picture n, it is in stored in modelOutput[n, i, j, k, :]
        """
        imageShape = featureDim[1:3]  # get the width and height of output feature map

        """
        step 1: pass tx, ty through sigmoid and offset by grid coordinates so that we get bx, by
        Let's assume the raw boxXY = (0,0) and it's in grid (0,1)
        """
        boxXY = tf.nn.sigmoid(modelOutput[..., :2])  # boxXY now w.r.t top left corner of its grid(on grid scale)
        """
        now boxXY = (0.5, 0.5). It means it's 0.5 (grid weight) and 0.5(grid height) away from the top left corner of grid (0,1)
        the red dot in figure 3 shows its location
        """
        idx = getOffset(imageShape) # convert box center to grid scale
        idx = tf.cast(idx, modelOutput.dtype)
        anchors = tf.cast(tf.reshape(anchors, (1, 1, 1, numAnchor, 2)), idx.dtype)
        boxXY = (boxXY + idx)  
        """
        idx essentially converts the boxXY coordinates from w.r.t its own grid(0,1) to the black top left corner of gird (0,0)
        now boxXY = (0.5,0.5) + (0,1) = (0.5, 1.5), meaning it's 0.5 grid height and 1.5 grid width from tht black dot 
        for two boxes k1 and k2, their local overlapps iff boxXY 1 == boxXY 2 & they are in the same grid
        """
        
        """
        step 2: convert box width and hight 
        let's assume boxWH = (0.4, 0.4) and its anchor box has size (0.75, 0.5), which is shown as the blue box
        """
        boxWH = tf.math.exp(modelOutput[..., 2:4]) 
        """
        Now boxWH = (1.5, 1.5), meaning it's 1.5 times wider and taller than the anchor box
        """
        boxWH = boxWH * anchors
        """
        Now boxWH = (1.13, 0.75), meaning its width is 0.75 unit of grid width and height is 1.13 units of grid height, shown as
        the red box in figure 3. As you can see, for different anchors, boxWH = (1.13, 0.75) means different sizes
        """
        objScore = tf.nn.sigmoid(modelOutput[..., 4:5])  # objectiveness score; must be between 0 and 1
        classProb = tf.nn.softmax(modelOutput[..., 5:])  # probability of classes; pass through a softmax gate to obtain prob.
        
        return boxXY, boxWH, objScore, classProb

            # # grid indices for future use
            # grid_x = np.tile(np.arange(grid_w).reshape(1, grid_w, 1), (grid_h, 1, anch_boxes))
            # grid_y = np.tile(np.arange(grid_h).reshape(grid_h, 1, 1), (1, grid_w, anch_boxes))

            # bound_box_x = (self.sigmoid(box_cords[..., 0]) + grid_x) / grid_w
            # bound_box_y = (self.sigmoid(box_cords[..., 1]) + grid_y) / grid_h
            # bound_box_w = self.anchors[index][:, 0] * np.exp(box_cords[..., 2]) / input_w
            # bound_box_h = self.anchors[index][:, 1] * np.exp(box_cords[..., 3]) / input_h

            # tl_x = (bound_box_x - bound_box_w / 2) * image_w
            # tl_y = (bound_box_y - bound_box_h / 2) * image_h
            # lr_x = (bound_box_x + bound_box_w / 2) * image_w
            # lr_y = bound_box_y + (bound_box_h / 2) * image_h
            # box_cords = np.stack([tl_x, tl_y, lr_x, lr_y], axis=-1)

            # boxes.append(box_cords)

                        # Trying a different approach I've seen
            for i in range(grid_h):
                for j in range(grid_w):
                    for anch_idx in range(anch_boxes):
                        # Initializing values
                        anch_w, anch_h = self.anchors[index][anch_idx]
                        print(f"Anchor width and height: {anch_w}, {anch_h}")
                        tx, ty, tw, th = box_cords[i, j, anch_idx]

                        # get boundary box center coordinates
                        bound_box_x = (self.sigmoid(tx) + j)
                        bound_box_y = (self.sigmoid(ty) + i)

                        # get width and height
                        bound_box_w = anch_w * np.exp(tw)
                        bound_box_h = anch_h * np.exp(th)

                        # normalization
                        bound_box_x /= grid_w
                        bound_box_y /= grid_h
                        bound_box_w /= int(input_w)
                        bound_box_h /= int(input_h)

                        # conversion to scale
                        tl_x = (bound_box_x - (bound_box_w / 2) * image_w)
                        tl_y = (bound_box_y - (bound_box_h / 2) * image_h)
                        lr_x = (bound_box_x + (bound_box_w / 2) * image_w)
                        lr_y = (bound_box_y + (bound_box_h / 2) * image_h)
                        box_cords[j, i, anch_idx] = [tl_x, tl_y, lr_x, lr_y]